{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5AHVVfZl6n3"
      },
      "source": [
        "### Importing Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW90fTLKMiKu"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, MaxPool2D, ZeroPadding2D\n",
        "from keras.layers import Conv2D, BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "TRAINING_DATA = 42000\n",
        "TEST_DATA = 18000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsce-2OpmC1t"
      },
      "source": [
        "### Loading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erihR4NmRIaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453f2722-ce42-44a6-d509-fdf0f5478d46"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-nwx6lCmpvp"
      },
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo_aw81Ad4hE",
        "outputId": "c266f75b-8341-4290-febc-4e2613b9deba"
      },
      "source": [
        "x = np.concatenate((x_train, x_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=55)\n",
        "print(\"Data after 70:30 split\")\n",
        "print(\"----------------------\\n\")\n",
        "print(\"X_train shape :\", x_train.shape)\n",
        "print(\"X_train shape :\", y_train.shape)\n",
        "print(\"X_train shape :\", x_test.shape)\n",
        "print(\"X_train shape :\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data after 70:30 split\n",
            "----------------------\n",
            "\n",
            "X_train shape : (42000, 32, 32, 3)\n",
            "X_train shape : (42000, 1)\n",
            "X_train shape : (18000, 32, 32, 3)\n",
            "X_train shape : (18000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGvASGGFrw18"
      },
      "source": [
        "### Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO93Zb6Nm98M"
      },
      "source": [
        "def normalize_data(x_train, x_test):\n",
        "    x_train = x_train / 255.0\n",
        "    x_test = x_test / 255.0\n",
        "    return x_train, x_test\n",
        "    \n",
        "x_train, x_test = normalize_data(x_train, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_lyOIwRr8fC"
      },
      "source": [
        "### Converting Labels to Categorical format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWuEJ5CARWts"
      },
      "source": [
        "def process_labels(y_train, y_test):\n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test = to_categorical(y_test)\n",
        "    return y_train, y_test\n",
        "\n",
        "y_train, y_test = process_labels(y_train, y_test)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XVntQImd9ev"
      },
      "source": [
        "### 1. Training Neural Net Without Batch Normalization (on Basic Architecture)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO8nAsXOeOht"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(ZeroPadding2D(padding=1))\n",
        "model.add(Conv2D(64, (5,5), input_shape = (32,32,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPool2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(optimizer = SGD(0.1), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "#plot_model(model1, to_file='cifar10_2_layer_architecture.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G7WZzBdfw2j"
      },
      "source": [
        "# Prevent over fitting we will stop the learning after 5 epochs and val_loss value not decreased\n",
        "earlystop = EarlyStopping(patience=5)\n",
        "\n",
        "# It will reduce the learning rate when accuracy is not increasing for 2 epochs\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB5FW4p3f4Ly",
        "outputId": "a22703a6-25fd-4069-9858-b4d2122fc395"
      },
      "source": [
        "# applying transformations to image\n",
        "train_gen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip = True)\n",
        "test_gen = ImageDataGenerator()\n",
        "\n",
        "training_set= train_gen.flow(x_train, y_train, batch_size = 64)\n",
        "test_set= train_gen.flow(x_test, y_test, batch_size = 64) \n",
        "\n",
        "history = model.fit_generator(training_set, \n",
        "                         steps_per_epoch = TRAINING_DATA//BATCH_SIZE,\n",
        "                         callbacks=callbacks, \n",
        "                         validation_data = test_set, \n",
        "                         validation_steps = TEST_DATA//BATCH_SIZE, \n",
        "                         epochs = 20)\n",
        "model.save('modelBasic.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "656/656 [==============================] - 82s 124ms/step - loss: 2.1098 - accuracy: 0.2208 - val_loss: 1.5429 - val_accuracy: 0.4464\n",
            "Epoch 2/20\n",
            "656/656 [==============================] - 80s 122ms/step - loss: 1.5819 - accuracy: 0.4332 - val_loss: 1.4255 - val_accuracy: 0.4882\n",
            "Epoch 3/20\n",
            "656/656 [==============================] - 79s 120ms/step - loss: 1.4410 - accuracy: 0.4836 - val_loss: 1.4507 - val_accuracy: 0.4813\n",
            "Epoch 4/20\n",
            "656/656 [==============================] - 80s 122ms/step - loss: 1.3752 - accuracy: 0.5086 - val_loss: 1.3272 - val_accuracy: 0.5246\n",
            "Epoch 5/20\n",
            "656/656 [==============================] - 80s 122ms/step - loss: 1.3217 - accuracy: 0.5282 - val_loss: 1.2367 - val_accuracy: 0.5619\n",
            "Epoch 6/20\n",
            "656/656 [==============================] - 80s 121ms/step - loss: 1.2758 - accuracy: 0.5464 - val_loss: 1.2348 - val_accuracy: 0.5576\n",
            "Epoch 7/20\n",
            "656/656 [==============================] - 79s 121ms/step - loss: 1.2483 - accuracy: 0.5584 - val_loss: 1.2100 - val_accuracy: 0.5726\n",
            "Epoch 8/20\n",
            "656/656 [==============================] - 79s 120ms/step - loss: 1.2214 - accuracy: 0.5653 - val_loss: 1.2157 - val_accuracy: 0.5731\n",
            "Epoch 9/20\n",
            "656/656 [==============================] - 79s 120ms/step - loss: 1.1981 - accuracy: 0.5748 - val_loss: 1.1706 - val_accuracy: 0.5871\n",
            "Epoch 10/20\n",
            "656/656 [==============================] - 78s 120ms/step - loss: 1.1784 - accuracy: 0.5806 - val_loss: 1.1886 - val_accuracy: 0.5830\n",
            "Epoch 11/20\n",
            "656/656 [==============================] - 79s 120ms/step - loss: 1.1534 - accuracy: 0.5941 - val_loss: 1.1736 - val_accuracy: 0.5884\n",
            "Epoch 12/20\n",
            "656/656 [==============================] - 79s 120ms/step - loss: 1.1446 - accuracy: 0.5969 - val_loss: 1.1230 - val_accuracy: 0.6048\n",
            "Epoch 13/20\n",
            "656/656 [==============================] - 79s 120ms/step - loss: 1.1054 - accuracy: 0.6105 - val_loss: 1.0766 - val_accuracy: 0.6223\n",
            "Epoch 14/20\n",
            "656/656 [==============================] - 78s 120ms/step - loss: 1.0898 - accuracy: 0.6154 - val_loss: 1.0917 - val_accuracy: 0.6113\n",
            "Epoch 15/20\n",
            "656/656 [==============================] - 79s 120ms/step - loss: 1.0784 - accuracy: 0.6192 - val_loss: 1.1041 - val_accuracy: 0.6118\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n",
            "Epoch 16/20\n",
            "656/656 [==============================] - 79s 120ms/step - loss: 1.0182 - accuracy: 0.6428 - val_loss: 1.0052 - val_accuracy: 0.6480\n",
            "Epoch 17/20\n",
            "656/656 [==============================] - 79s 120ms/step - loss: 0.9889 - accuracy: 0.6523 - val_loss: 1.0168 - val_accuracy: 0.6411\n",
            "Epoch 18/20\n",
            "656/656 [==============================] - 79s 121ms/step - loss: 0.9900 - accuracy: 0.6513 - val_loss: 0.9982 - val_accuracy: 0.6489\n",
            "Epoch 19/20\n",
            "656/656 [==============================] - 79s 121ms/step - loss: 0.9741 - accuracy: 0.6540 - val_loss: 0.9995 - val_accuracy: 0.6509\n",
            "Epoch 20/20\n",
            "656/656 [==============================] - 79s 121ms/step - loss: 0.9693 - accuracy: 0.6595 - val_loss: 0.9967 - val_accuracy: 0.6510\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aErwx-H0sMJv"
      },
      "source": [
        "### 2. Training Neural Net without Batch Normalization (2 Conv2D Layers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtVNpHBbTD1b"
      },
      "source": [
        "model1 = Sequential()\n",
        "\n",
        "model1.add(Conv2D(64, (5,5), input_shape = (32,32,3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPool2D(pool_size = (2,2)))\n",
        "\n",
        "model1.add(Conv2D(128, (3,3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPool2D(pool_size = (2,2)))\n",
        "model1.add(Dropout(0.1))\n",
        "\n",
        "model1.add(Flatten())\n",
        "\n",
        "model1.add(Dense(64))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(Dropout(0.1))\n",
        "\n",
        "model1.add(Dense(10))\n",
        "model1.add(Activation('softmax'))\n",
        "\n",
        "model1.compile(optimizer = SGD(0.1), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "#plot_model(model1, to_file='cifar10_2_layer_architecture.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYP-pTREhsfa"
      },
      "source": [
        "# Prevent over fitting we will stop the learning after 5 epochs and val_loss value not decreased\n",
        "earlystop = EarlyStopping(patience=5)\n",
        "\n",
        "# It will reduce the learning rate when accuracy is not increasing for 2 epochs\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yM9Yf-qXq-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f446bf-5445-48c6-9c7d-a3b7711f0333"
      },
      "source": [
        "# applying transformations to image\n",
        "train_gen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip = True)\n",
        "test_gen = ImageDataGenerator()\n",
        "\n",
        "training_set= train_gen.flow(x_train, y_train, batch_size = 64)\n",
        "test_set= train_gen.flow(x_test, y_test, batch_size = 64) \n",
        "\n",
        "history = model1.fit_generator(training_set, \n",
        "                         steps_per_epoch = TRAINING_DATA//BATCH_SIZE,\n",
        "                         callbacks=callbacks, \n",
        "                         validation_data = test_set, \n",
        "                         validation_steps = TEST_DATA//BATCH_SIZE, \n",
        "                         epochs = 20)\n",
        "model1.save('modelA.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "656/656 [==============================] - 143s 217ms/step - loss: 2.0994 - accuracy: 0.2242 - val_loss: 1.5742 - val_accuracy: 0.4320\n",
            "Epoch 2/20\n",
            "656/656 [==============================] - 142s 216ms/step - loss: 1.5662 - accuracy: 0.4341 - val_loss: 1.3683 - val_accuracy: 0.5144\n",
            "Epoch 3/20\n",
            "656/656 [==============================] - 143s 218ms/step - loss: 1.3864 - accuracy: 0.5021 - val_loss: 1.2519 - val_accuracy: 0.5595\n",
            "Epoch 4/20\n",
            "656/656 [==============================] - 144s 220ms/step - loss: 1.2818 - accuracy: 0.5413 - val_loss: 1.1607 - val_accuracy: 0.5846\n",
            "Epoch 5/20\n",
            "656/656 [==============================] - 144s 219ms/step - loss: 1.2071 - accuracy: 0.5719 - val_loss: 1.1528 - val_accuracy: 0.5925\n",
            "Epoch 6/20\n",
            "656/656 [==============================] - 143s 218ms/step - loss: 1.1598 - accuracy: 0.5889 - val_loss: 1.1600 - val_accuracy: 0.5954\n",
            "Epoch 7/20\n",
            "656/656 [==============================] - 144s 219ms/step - loss: 1.1070 - accuracy: 0.6146 - val_loss: 1.0433 - val_accuracy: 0.6299\n",
            "Epoch 8/20\n",
            "656/656 [==============================] - 143s 218ms/step - loss: 1.0642 - accuracy: 0.6261 - val_loss: 1.0458 - val_accuracy: 0.6302\n",
            "Epoch 9/20\n",
            "656/656 [==============================] - 142s 217ms/step - loss: 1.0321 - accuracy: 0.6397 - val_loss: 0.9879 - val_accuracy: 0.6571\n",
            "Epoch 10/20\n",
            "656/656 [==============================] - 142s 217ms/step - loss: 0.9832 - accuracy: 0.6532 - val_loss: 1.1209 - val_accuracy: 0.6165\n",
            "Epoch 11/20\n",
            "656/656 [==============================] - 143s 218ms/step - loss: 0.9886 - accuracy: 0.6515 - val_loss: 0.9571 - val_accuracy: 0.6624\n",
            "Epoch 12/20\n",
            "656/656 [==============================] - 143s 219ms/step - loss: 0.9554 - accuracy: 0.6619 - val_loss: 0.9802 - val_accuracy: 0.6638\n",
            "Epoch 13/20\n",
            "656/656 [==============================] - 143s 219ms/step - loss: 0.9349 - accuracy: 0.6742 - val_loss: 0.9139 - val_accuracy: 0.6845\n",
            "Epoch 14/20\n",
            "656/656 [==============================] - 143s 217ms/step - loss: 0.9114 - accuracy: 0.6809 - val_loss: 0.9291 - val_accuracy: 0.6718\n",
            "Epoch 15/20\n",
            "656/656 [==============================] - 145s 221ms/step - loss: 0.8821 - accuracy: 0.6913 - val_loss: 0.8902 - val_accuracy: 0.6896\n",
            "Epoch 16/20\n",
            "656/656 [==============================] - 144s 219ms/step - loss: 0.8667 - accuracy: 0.6932 - val_loss: 0.9313 - val_accuracy: 0.6764\n",
            "Epoch 17/20\n",
            "656/656 [==============================] - 144s 219ms/step - loss: 0.8531 - accuracy: 0.7028 - val_loss: 0.8758 - val_accuracy: 0.6946\n",
            "Epoch 18/20\n",
            "656/656 [==============================] - 143s 218ms/step - loss: 0.8384 - accuracy: 0.7058 - val_loss: 0.8765 - val_accuracy: 0.6968\n",
            "Epoch 19/20\n",
            "656/656 [==============================] - 142s 217ms/step - loss: 0.8321 - accuracy: 0.7082 - val_loss: 0.8568 - val_accuracy: 0.6998\n",
            "Epoch 20/20\n",
            "656/656 [==============================] - 142s 217ms/step - loss: 0.8196 - accuracy: 0.7145 - val_loss: 0.8639 - val_accuracy: 0.6992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VK5rkkLvu2B"
      },
      "source": [
        "### 3. Training with Batch Normalization and 2 Conv2D Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX73SrPPwSpL"
      },
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Conv2D(64, (5,5), input_shape=(32,32,3)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPool2D(pool_size = (2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "model2.add(Conv2D(128, (3,3)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPool2D(pool_size = (2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "model2.add(Flatten())\n",
        "\n",
        "model2.add(Dense(64))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.1))\n",
        "\n",
        "model2.add(Dense(10))\n",
        "model2.add(Activation('softmax'))\n",
        "\n",
        "model2.compile(optimizer = SGD(0.1), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "#plot_model(model2, to_file='cifar10_2_layer_with_batchNorm_architecture.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnbF-2HOhkFc"
      },
      "source": [
        "# To prevent over fitting we will stop the learning after 5 epochs and val_loss value not decreased\n",
        "earlystop = EarlyStopping(patience=5)\n",
        "\n",
        "# It will reduce the learning rate when accuracy is not increasing for 2 epochs\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuLP6KhOwejg",
        "outputId": "99eb6b15-4c29-47d3-8aa2-1cd8e759f035"
      },
      "source": [
        "# applying transformation to image\n",
        "train_gen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "test_gen = ImageDataGenerator()\n",
        "\n",
        "training_set= train_gen.flow(x_train, y_train, batch_size = 64)\n",
        "test_set= train_gen.flow(x_test, y_test, batch_size = 64)\n",
        "\n",
        "history2 = model2.fit_generator(training_set, \n",
        "                         steps_per_epoch = TRAINING_DATA//BATCH_SIZE,\n",
        "                         callbacks=callbacks, \n",
        "                         validation_data = test_set, \n",
        "                         validation_steps = TEST_DATA//BATCH_SIZE, \n",
        "                         epochs = 20)\n",
        "\n",
        "model2.save('modelB.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "656/656 [==============================] - 156s 236ms/step - loss: 1.7284 - accuracy: 0.3797 - val_loss: 1.4687 - val_accuracy: 0.4715\n",
            "Epoch 2/20\n",
            "656/656 [==============================] - 154s 235ms/step - loss: 1.2986 - accuracy: 0.5316 - val_loss: 1.2539 - val_accuracy: 0.5507\n",
            "Epoch 3/20\n",
            "656/656 [==============================] - 154s 235ms/step - loss: 1.1749 - accuracy: 0.5789 - val_loss: 1.7031 - val_accuracy: 0.4537\n",
            "Epoch 4/20\n",
            "656/656 [==============================] - 154s 235ms/step - loss: 1.0933 - accuracy: 0.6139 - val_loss: 1.1110 - val_accuracy: 0.6040\n",
            "Epoch 5/20\n",
            "656/656 [==============================] - 154s 235ms/step - loss: 1.0389 - accuracy: 0.6339 - val_loss: 0.9936 - val_accuracy: 0.6453\n",
            "Epoch 6/20\n",
            "656/656 [==============================] - 154s 235ms/step - loss: 0.9921 - accuracy: 0.6467 - val_loss: 1.1890 - val_accuracy: 0.5801\n",
            "Epoch 7/20\n",
            "656/656 [==============================] - 154s 235ms/step - loss: 0.9601 - accuracy: 0.6623 - val_loss: 1.1013 - val_accuracy: 0.6119\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n",
            "Epoch 8/20\n",
            "656/656 [==============================] - 154s 235ms/step - loss: 0.9004 - accuracy: 0.6850 - val_loss: 0.8726 - val_accuracy: 0.6949\n",
            "Epoch 9/20\n",
            "656/656 [==============================] - 154s 235ms/step - loss: 0.8716 - accuracy: 0.6917 - val_loss: 0.8460 - val_accuracy: 0.7008\n",
            "Epoch 10/20\n",
            "656/656 [==============================] - 154s 234ms/step - loss: 0.8389 - accuracy: 0.7068 - val_loss: 0.8657 - val_accuracy: 0.7010\n",
            "Epoch 11/20\n",
            "656/656 [==============================] - 154s 234ms/step - loss: 0.8331 - accuracy: 0.7093 - val_loss: 0.8462 - val_accuracy: 0.7026\n",
            "Epoch 12/20\n",
            "656/656 [==============================] - 153s 234ms/step - loss: 0.8237 - accuracy: 0.7125 - val_loss: 0.8681 - val_accuracy: 0.6977\n",
            "Epoch 13/20\n",
            "656/656 [==============================] - 153s 234ms/step - loss: 0.8089 - accuracy: 0.7172 - val_loss: 0.8025 - val_accuracy: 0.7200\n",
            "Epoch 14/20\n",
            "656/656 [==============================] - 153s 234ms/step - loss: 0.8037 - accuracy: 0.7193 - val_loss: 0.8294 - val_accuracy: 0.7058\n",
            "Epoch 15/20\n",
            "656/656 [==============================] - 154s 234ms/step - loss: 0.7974 - accuracy: 0.7184 - val_loss: 0.8509 - val_accuracy: 0.7025\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
            "Epoch 16/20\n",
            "656/656 [==============================] - 153s 233ms/step - loss: 0.7565 - accuracy: 0.7356 - val_loss: 0.7334 - val_accuracy: 0.7417\n",
            "Epoch 17/20\n",
            "656/656 [==============================] - 152s 232ms/step - loss: 0.7488 - accuracy: 0.7386 - val_loss: 0.7344 - val_accuracy: 0.7402\n",
            "Epoch 18/20\n",
            "656/656 [==============================] - 153s 233ms/step - loss: 0.7470 - accuracy: 0.7383 - val_loss: 0.7464 - val_accuracy: 0.7367\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
            "Epoch 19/20\n",
            "656/656 [==============================] - 153s 234ms/step - loss: 0.7231 - accuracy: 0.7450 - val_loss: 0.7205 - val_accuracy: 0.7476\n",
            "Epoch 20/20\n",
            "656/656 [==============================] - 154s 234ms/step - loss: 0.7187 - accuracy: 0.7507 - val_loss: 0.7586 - val_accuracy: 0.7348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuyOw2Ljw0UG"
      },
      "source": [
        "### 4. Training after adding one more Conv2D layer (3 Conv2D Layers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BlxacfpwecZ"
      },
      "source": [
        "model3 = Sequential()\n",
        "\n",
        "model3.add(Conv2D(64, (5,5), input_shape=(32,32,3)))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(MaxPool2D(pool_size = (2,2)))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "\n",
        "model3.add(Conv2D(128, (3,3)))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(MaxPool2D(pool_size = (2,2)))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "\n",
        "model3.add(Conv2D(256, (3,3)))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(MaxPool2D(pool_size = (2,2)))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "\n",
        "model3.add(Flatten())\n",
        "\n",
        "model3.add(Dense(64))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(Dropout(0.1))\n",
        "\n",
        "model3.add(Dense(10))\n",
        "model3.add(Activation('softmax'))\n",
        "\n",
        "model3.compile(optimizer = SGD(0.1), loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "#plot_model(model3, to_file='cifar10_3_layer_architecture.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1Zz066jilQk"
      },
      "source": [
        "# To prevent over fitting we will stop the learning after 5 epochs and val_loss value not decreased\n",
        "earlystop = EarlyStopping(patience=5)\n",
        "\n",
        "# It will reduce the learning rate when accuracy is not increasing for 2 epochs\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mpd0t50zZQG",
        "outputId": "fa6021f5-3d86-499d-a1d4-bc2e8b68e793"
      },
      "source": [
        "# applying transformation to image\n",
        "train_gen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "test_gen = ImageDataGenerator()\n",
        "\n",
        "training_set= train_gen.flow(x_train, y_train, batch_size = 64)\n",
        "test_set= train_gen.flow(x_test, y_test, batch_size = 64)\n",
        "\n",
        "history3 = model3.fit_generator(training_set, \n",
        "                         steps_per_epoch = TRAINING_DATA//BATCH_SIZE, \n",
        "                         validation_data = test_set,\n",
        "                         callbacks=callbacks, \n",
        "                         validation_steps = TEST_DATA//BATCH_SIZE, \n",
        "                         epochs = 20)\n",
        "\n",
        "model3.save('modelC.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "656/656 [==============================] - 203s 309ms/step - loss: 1.7808 - accuracy: 0.3675 - val_loss: 2.0796 - val_accuracy: 0.3040\n",
            "Epoch 2/20\n",
            "656/656 [==============================] - 203s 309ms/step - loss: 1.3298 - accuracy: 0.5197 - val_loss: 1.2262 - val_accuracy: 0.5596\n",
            "Epoch 3/20\n",
            "656/656 [==============================] - 203s 309ms/step - loss: 1.1940 - accuracy: 0.5731 - val_loss: 1.1083 - val_accuracy: 0.6102\n",
            "Epoch 4/20\n",
            "656/656 [==============================] - 203s 309ms/step - loss: 1.1051 - accuracy: 0.6055 - val_loss: 1.1058 - val_accuracy: 0.6144\n",
            "Epoch 5/20\n",
            "656/656 [==============================] - 202s 309ms/step - loss: 1.0318 - accuracy: 0.6337 - val_loss: 1.0223 - val_accuracy: 0.6453\n",
            "Epoch 6/20\n",
            "656/656 [==============================] - 202s 308ms/step - loss: 0.9870 - accuracy: 0.6516 - val_loss: 1.2232 - val_accuracy: 0.5710\n",
            "Epoch 7/20\n",
            "656/656 [==============================] - 202s 308ms/step - loss: 0.9359 - accuracy: 0.6725 - val_loss: 1.1317 - val_accuracy: 0.6032\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n",
            "Epoch 8/20\n",
            "656/656 [==============================] - 203s 309ms/step - loss: 0.8452 - accuracy: 0.7032 - val_loss: 0.8496 - val_accuracy: 0.7037\n",
            "Epoch 9/20\n",
            "656/656 [==============================] - 202s 308ms/step - loss: 0.8103 - accuracy: 0.7177 - val_loss: 0.7859 - val_accuracy: 0.7274\n",
            "Epoch 10/20\n",
            "656/656 [==============================] - 203s 309ms/step - loss: 0.7858 - accuracy: 0.7264 - val_loss: 0.8198 - val_accuracy: 0.7102\n",
            "Epoch 11/20\n",
            "656/656 [==============================] - 202s 308ms/step - loss: 0.7790 - accuracy: 0.7305 - val_loss: 0.7967 - val_accuracy: 0.7199\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
            "Epoch 12/20\n",
            "656/656 [==============================] - 202s 308ms/step - loss: 0.7380 - accuracy: 0.7416 - val_loss: 0.7307 - val_accuracy: 0.7456\n",
            "Epoch 13/20\n",
            "656/656 [==============================] - 201s 306ms/step - loss: 0.7257 - accuracy: 0.7498 - val_loss: 0.7521 - val_accuracy: 0.7388\n",
            "Epoch 14/20\n",
            "656/656 [==============================] - 201s 307ms/step - loss: 0.7111 - accuracy: 0.7522 - val_loss: 0.7277 - val_accuracy: 0.7457\n",
            "Epoch 15/20\n",
            "656/656 [==============================] - 201s 307ms/step - loss: 0.7052 - accuracy: 0.7563 - val_loss: 0.7475 - val_accuracy: 0.7405\n",
            "Epoch 16/20\n",
            "656/656 [==============================] - 201s 307ms/step - loss: 0.6918 - accuracy: 0.7594 - val_loss: 0.7079 - val_accuracy: 0.7534\n",
            "Epoch 17/20\n",
            "656/656 [==============================] - 202s 307ms/step - loss: 0.6857 - accuracy: 0.7594 - val_loss: 0.7023 - val_accuracy: 0.7596\n",
            "Epoch 18/20\n",
            "656/656 [==============================] - 201s 307ms/step - loss: 0.6649 - accuracy: 0.7654 - val_loss: 0.6783 - val_accuracy: 0.7654\n",
            "Epoch 19/20\n",
            "656/656 [==============================] - 201s 307ms/step - loss: 0.6638 - accuracy: 0.7685 - val_loss: 0.7848 - val_accuracy: 0.7315\n",
            "Epoch 20/20\n",
            "656/656 [==============================] - 202s 307ms/step - loss: 0.6688 - accuracy: 0.7682 - val_loss: 0.6975 - val_accuracy: 0.7582\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnPylJkqb5cb"
      },
      "source": [
        "### Comparision b/w Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN6pcbKNb_6_",
        "outputId": "728bb9e2-e79e-4c0c-f4c4-8dcbb79f2541"
      },
      "source": [
        "print(\"Accuracy STATS :\")\n",
        "print(\"----------------\\n\")\n",
        "\n",
        "print(\"Model with Basic Architecture : \") \n",
        "model.evaluate(x_test,y_test)\n",
        "print(\"Model A : \") \n",
        "model1.evaluate(x_test,y_test)\n",
        "print(\"Model B : \") \n",
        "model2.evaluate(x_test,y_test)\n",
        "print(\"Model C : \") \n",
        "model3.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy STATS :\n",
            "----------------\n",
            "\n",
            "Model with Basic Architecture : \n",
            "563/563 [==============================] - 8s 14ms/step - loss: 0.9047 - accuracy: 0.6891\n",
            "Model A : \n",
            "563/563 [==============================] - 14s 24ms/step - loss: 0.7851 - accuracy: 0.7253\n",
            "Model B : \n",
            "563/563 [==============================] - 15s 26ms/step - loss: 0.7397 - accuracy: 0.7397\n",
            "Model C : \n",
            "563/563 [==============================] - 18s 31ms/step - loss: 0.6139 - accuracy: 0.7851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6138617992401123, 0.785111129283905]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JRvpI6HhDxF"
      },
      "source": [
        "### Saving Summary for Best Model (MODEL 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13LrbUCJhDes",
        "outputId": "bdb2efd1-c046-426e-a301-908ae9326803"
      },
      "source": [
        "with open(\"summary_q1\",\"w\") as fh:\n",
        "    model3.summary(print_fn=lambda line: fh.write(line + \"\\n\"))\n",
        "\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 28, 28, 64)        4864      \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 442,186\n",
            "Trainable params: 441,162\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5h5SqVU0-sM"
      },
      "source": [
        "### Epochs Vs Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "eQa9aEjax4Re",
        "outputId": "a2f283b8-72ee-447f-a20c-784fb1e09b59"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_facecolor('w')\n",
        "ax.grid(b=False)\n",
        "ax.plot(history3.history['accuracy'], color='red')\n",
        "ax.plot(history3.history['val_accuracy'], color ='green')\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}